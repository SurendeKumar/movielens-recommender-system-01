# Movie Recommender System

A conversational AI movie assistant built with **FastAPI**, **SQLite**, and **Large Language Models (LLMs)**.  

The system combines structured data retrieval (SQLite) with natural language generation (LLMs) to provide interactive, conversational answers about movies.

---

## Features

- Local **SQLite** database (movies, genres, ratings, cast, director, overview)  
- Dataset ingestion from **MovieLens 100K** or **TMDB 5000**  
- REST API with **FastAPI** and auto-generated docs  
- Hybrid approach: **SQL for accuracy** + **LLM for conversational responses**  
- Deployable with **Docker**  

---

## Project Structure

```
movie-recommender_system-01/
â”‚
â”œâ”€â”€ movie_reccommender_system/        # Core agent logic (intents, LLM orchestration)
    â””â”€â”€data_ingestor/      # Dataset ingestion scripts
    â”œâ”€â”€ db/
         â””â”€â”€ movies.db      # SQLite database (generated after ingestion)
    â”œâ”€â”€ utilities/          # Helper scripts (logging, config, prompts)
    â”œâ”€â”€ data_raw/           # Raw datasets (unzipped Kaggle/TMDB files)
    â”œâ”€â”€ llm_cient/          # LLM Client for conversation recommender system
â”œâ”€â”€ tests/              # Unit & integration tests
â”œâ”€â”€ router/             # FastAPI routers (API endpoints)
â”œâ”€â”€ app.py              # FastAPI entrypoint
â”œâ”€â”€ startup.sh          # Startup script
â”œâ”€â”€ Dockerfile          # Docker build file
â”œâ”€â”€ docker-compose.yml  # Docker Compose config
â”œâ”€â”€ .env                # Environment variables (DB path, LLM config, API keys)
â”œâ”€â”€ pyproject.toml      # Python dependencies - pkg manager
â””â”€â”€ README.md           # outline the package details
```

---

## Setup Instructions

### 1. Clone the repository
```bash
git clone https://github.com/SurendeKumar/movielens-recommender-system-01
cd movielens-recommender-system-01
```

### 2. Create a virtual environment
```bash
- python -m venv .venv

- Install with editable mode: pip install -e .
- Install with editable mode and also extra dependencies under .dev inside tom file (mainly for testing): pip install -e .[dev]

```

Activate it:

- **macOS/Linux**
  ```bash
  source .venv/bin/activate
  ```
- **Windows (PowerShell)**
  ```powershell
  .venv\Scripts\activate
  ```

### 3. Install dependencies
```bash
pip install -e .
pip install -e .[dev]
```

### 4. Download dataset
- Download **MovieLens 100K** or **TMDB 5000 Movie Dataset** from Kaggle  
- Unzip the files  
- Place them into the `data_raw/` directory  

### 5. Run data ingestion
```bash
python -m data_ingestor.load_data
```

This step will:
- Parse the raw dataset  
- Normalize movies, genres, and ratings  
- Create and populate the SQLite database at:
  ```
  db/movies.db
  ```

### 6. Start the FastAPI application
```bash
uvicorn app:app --reload
./startup.ps1 (Windows (PowerShell))
./startup.sh (macOS/Linux - save .ps1 as .sh)
```

## API Endpoints

- `GET /version` â†’ API Version check
- `GET /status` â†’ API status check


---

## LLM Integration

Supports multiple providers (via `.env` config):  
- **Hugging Face Transformers** (local or hosted)  
- **Ollama** (local inference)  
- **OpenAI API** (`gpt-4o-mini`, `gpt-4.1`)  

LLMs are used to:  
- Phrase results conversationally  
- Explain recommendations  
- Handle ambiguous queries with clarifying questions  

---

## Running with Docker

Build and start with Docker Compose:
```bash
docker-compose up --build
```

---

## Testing

Run tests with:
```bash
pytest tests/
```

---

**How the system works so far???**

Part 1: **Data Ingestion**
----------------------------

Goal: Get MovieLens data into your SQLite DB, normalize genres, and compute stats.

### Steps:

1.  uvicorn app:app --reload (assuming your entrypoint is app.py with app = FastAPI())
    
2.  OR run everything in one go:
    
    *   POST /ingest/data-insertion â†’ loads u.item + u.data â†’ inserts movies and ratings.
        
    *   POST /ingest/genres â†’ builds genres + movie\_genres.
        
    *   POST /ingest/movie-ratings-stats â†’ computes avg\_rating + num\_ratings.
        
    
    *   POST /ingest/data-ingestor â†’ runs all 3 steps in sequence.
        
        
3.  **Check results in logs/DB**
    
    *   Logs show inserted counts, genres created, movies updated.
        
    *   sqlite3 movie\_reccommender\_system/db/movies.dbsqlite> .tablessqlite> SELECT COUNT(\*) FROM movies;
        

Part 2: **Query Processing**
------------------------------

Goal: Parse natural language queries â†’ detect intent + slots â†’ run SQL to fetch results.

### Steps:

1.  **Keep FastAPI app running** (same as above).
    
2.  **Call query endpoints:**
    
    *   { "text": "recommend action movies from 2020" }
        
    *   { "text": "recommend action movies from 2020", "limit": 5 }
        
3.  **Check logs**
    
    *   Youâ€™ll see info logs for parsing, SQL execution, and number of rows returned.
        

ðŸ”„ Run Flow in Order
--------------------

So when starting fresh, the order is:

1.  **Ingest data**
    
    *   Call POST /ingest/data-ingestor once.
        
    *   Confirms DB is ready with movies, ratings, genres, stats.
        
2.  **Query processing**
    
    *   Call POST /query/parse (if you want to debug parser).
        
    *   Call POST /query/execute to actually get movie results.
